{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22242785-9bea-4765-9739-4f51e4a1af77",
   "metadata": {},
   "source": [
    "# Document processing with Amazon Nova Understanding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837dbd7-84c0-49da-8f00-b9b82cb1f51f",
   "metadata": {},
   "source": [
    "In this notebook we will demonstrate how to use [Amazon Nova *understanding* models](https://aws.amazon.com/ai/generative-ai/nova/) to extract information directly from binary documents.\n",
    "\n",
    "Among Amazon's Nova more interesting features is its document support, which means we no longer need to transform documents such as PDFs or Doc without the need to extract the document's text using an OCR first. See more at: [https://docs.aws.amazon.com/nova/latest/userguide/modalities-document.html](https://docs.aws.amazon.com/nova/latest/userguide/modalities-document.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf4253-7ea3-4862-a0a9-fa2f96504204",
   "metadata": {},
   "source": [
    "To execute the cells in this notebook you need to enable access to the following models on Bedrock:\n",
    "\n",
    "* Amazon Nova Pro\n",
    "\n",
    "see [Add or remove access to Amazon Bedrock foundation models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html) to manage the access to models in Amazon Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f18ae9-816c-481e-87fb-244789d280b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T23:35:03.273380Z",
     "iopub.status.busy": "2025-01-02T23:35:03.272750Z",
     "iopub.status.idle": "2025-01-02T23:35:03.295950Z",
     "shell.execute_reply": "2025-01-02T23:35:03.294106Z",
     "shell.execute_reply.started": "2025-01-02T23:35:03.273344Z"
    }
   },
   "source": [
    "Note: This notebook uses [Langchain](https://www.langchain.com/) to orchestrate the flow of the generative AI application. We make use of some Langchain \n",
    "features such as [prompt_selectors](https://blog.langchain.dev/prompt-selectors/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feeaa0b-a959-444e-bda2-916e7b0b2aeb",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca267cbc-f426-4d26-b083-5f15dd305ea3",
   "metadata": {},
   "source": [
    "The following packages are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b35d98-cf63-40aa-8594-79be96a2ab08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:49:59.350501Z",
     "iopub.status.busy": "2025-01-12T03:49:59.350019Z",
     "iopub.status.idle": "2025-01-12T03:50:12.852253Z",
     "shell.execute_reply": "2025-01-12T03:50:12.851257Z",
     "shell.execute_reply.started": "2025-01-12T03:49:59.350473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (2.9.2)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: langchain-aws in /opt/conda/lib/python3.11/site-packages (0.1.18)\n",
      "Collecting langchain-aws\n",
      "  Using cached langchain_aws-0.2.10-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: langchain-core in /opt/conda/lib/python3.11/site-packages (0.2.43)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.11/site-packages (0.2.17)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic)\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from pydantic) (4.12.2)\n",
      "Collecting boto3>=1.35.74 (from langchain-aws)\n",
      "  Using cached boto3-1.35.97-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-aws) (1.26.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
      "Collecting botocore<1.36.0,>=1.35.97 (from boto3>=1.35.74->langchain-aws)\n",
      "  Using cached botocore-1.35.97-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.35.74->langchain-aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.35.74->langchain-aws) (0.10.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.97->boto3>=1.35.74->langchain-aws) (2.9.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.97->boto3>=1.35.74->langchain-aws) (1.16.0)\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached langchain_aws-0.2.10-py3-none-any.whl (88 kB)\n",
      "Using cached langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "Using cached boto3-1.35.97-py3-none-any.whl (139 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Using cached botocore-1.35.97-py3-none-any.whl (13.3 MB)\n",
      "Installing collected packages: pydantic-core, pydantic, botocore, langchain-core, boto3, langchain-text-splitters, langchain-aws, langchain\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.23.4\n",
      "    Uninstalling pydantic_core-2.23.4:\n",
      "      Successfully uninstalled pydantic_core-2.23.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.2\n",
      "    Uninstalling pydantic-2.9.2:\n",
      "      Successfully uninstalled pydantic-2.9.2\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.162\n",
      "    Uninstalling botocore-1.34.162:\n",
      "      Successfully uninstalled botocore-1.34.162\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.43\n",
      "    Uninstalling langchain-core-0.2.43:\n",
      "      Successfully uninstalled langchain-core-0.2.43\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.162\n",
      "    Uninstalling boto3-1.34.162:\n",
      "      Successfully uninstalled boto3-1.34.162\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.2.4\n",
      "    Uninstalling langchain-text-splitters-0.2.4:\n",
      "      Successfully uninstalled langchain-text-splitters-0.2.4\n",
      "  Attempting uninstall: langchain-aws\n",
      "    Found existing installation: langchain-aws 0.1.18\n",
      "    Uninstalling langchain-aws-0.1.18:\n",
      "      Successfully uninstalled langchain-aws-0.1.18\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.17\n",
      "    Uninstalling langchain-0.2.17:\n",
      "      Successfully uninstalled langchain-0.2.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "aiobotocore 2.13.3 requires botocore<1.34.163,>=1.34.70, but you have botocore 1.35.97 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires torch<2.4,>=2.2, but you have torch 2.4.1.post100 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires torch<2.4,>=2.2, but you have torch 2.4.1.post100 which is incompatible.\n",
      "jupyter-ai-magics 2.28.1 requires langchain<0.3.0,>=0.1.0, but you have langchain 0.3.14 which is incompatible.\n",
      "langchain-community 0.2.19 requires langchain<0.3.0,>=0.2.17, but you have langchain 0.3.14 which is incompatible.\n",
      "langchain-community 0.2.19 requires langchain-core<0.3.0,>=0.2.43, but you have langchain-core 0.3.29 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.35.97 botocore-1.35.97 langchain-0.3.14 langchain-aws-0.2.10 langchain-core-0.3.29 langchain-text-splitters-0.3.5 pydantic-2.10.5 pydantic-core-2.27.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pydantic langchain-aws langchain-core langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4da32e-272c-4c11-92e5-b559017d0cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:17.641355Z",
     "iopub.status.busy": "2025-01-12T03:50:17.640878Z",
     "iopub.status.idle": "2025-01-12T03:50:19.418900Z",
     "shell.execute_reply": "2025-01-12T03:50:19.418172Z",
     "shell.execute_reply.started": "2025-01-12T03:50:17.641320Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import langchain_core\n",
    "import pydantic\n",
    "import base64\n",
    "import time\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from prompt_selector.information_extraction_prompt_selector import get_information_extraction_prompt_selector\n",
    "from structured_output.information_extraction import InformationExtraction\n",
    "\n",
    "from information_definition.CharterReports import InformacionGeneral, CapitalSocial, InformacionAdministracion, RepresentanteLegal, InformacionNotario\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b889c570-4bc8-4877-9b3a-4533595bb7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:19.420830Z",
     "iopub.status.busy": "2025-01-12T03:50:19.420324Z",
     "iopub.status.idle": "2025-01-12T03:50:19.761199Z",
     "shell.execute_reply": "2025-01-12T03:50:19.756658Z",
     "shell.execute_reply.started": "2025-01-12T03:50:19.420799Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=Config(retries={'max_attempts': 20})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767f5d4a-acc2-44e7-a29e-a66ee7ed20cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:19.764307Z",
     "iopub.status.busy": "2025-01-12T03:50:19.763664Z",
     "iopub.status.idle": "2025-01-12T03:50:19.769426Z",
     "shell.execute_reply": "2025-01-12T03:50:19.768784Z",
     "shell.execute_reply.started": "2025-01-12T03:50:19.764280Z"
    }
   },
   "outputs": [],
   "source": [
    "langchain_core.globals.set_debug(True) # Set to True for enabling debugging stack traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691a75c-2977-4fe9-a266-601c9c177f6a",
   "metadata": {},
   "source": [
    "## Load Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef73bf-9ae0-43d1-b8b0-1f6569855c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T23:38:36.708219Z",
     "iopub.status.busy": "2025-01-02T23:38:36.707857Z",
     "iopub.status.idle": "2025-01-02T23:38:36.730328Z",
     "shell.execute_reply": "2025-01-02T23:38:36.727289Z",
     "shell.execute_reply.started": "2025-01-02T23:38:36.708179Z"
    }
   },
   "source": [
    "For this exercise we will extract data from a charter report. A charter report is a legal document that specifies how a society is formed, its duties, shareholders and management. The sample charter report is in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59329cf2-6806-4c4f-bf60-eeeeab86f520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:20.056413Z",
     "iopub.status.busy": "2025-01-12T03:50:20.054125Z",
     "iopub.status.idle": "2025-01-12T03:50:20.064209Z",
     "shell.execute_reply": "2025-01-12T03:50:20.063289Z",
     "shell.execute_reply.started": "2025-01-12T03:50:20.056372Z"
    }
   },
   "outputs": [],
   "source": [
    "# read document as bytes\n",
    "with open('./sample_documents/acta_constitutiva.pdf', \"rb\") as file:\n",
    "    doc_bytes = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2c48b-3395-4430-80bd-4a6630cf223b",
   "metadata": {},
   "source": [
    "## Simple information extraction techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8037aef-9ed9-4dae-a89f-19389a15547c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:20.920302Z",
     "iopub.status.busy": "2025-01-12T03:50:20.919716Z",
     "iopub.status.idle": "2025-01-12T03:50:20.924557Z",
     "shell.execute_reply": "2025-01-12T03:50:20.923688Z",
     "shell.execute_reply.started": "2025-01-12T03:50:20.920275Z"
    }
   },
   "outputs": [],
   "source": [
    "INFORMATION_EXTRACTION_MODEL_PARAMETERS = {\n",
    "    \"max_tokens\": 1500,\n",
    "    \"temperature\": 0.3, # Low temperature since we want to extract data\n",
    "    \"top_k\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d703cd05-fc04-4608-94ea-1ef7412cc509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:21.455450Z",
     "iopub.status.busy": "2025-01-12T03:50:21.454857Z",
     "iopub.status.idle": "2025-01-12T03:50:21.467811Z",
     "shell.execute_reply": "2025-01-12T03:50:21.464475Z",
     "shell.execute_reply.started": "2025-01-12T03:50:21.455421Z"
    }
   },
   "outputs": [],
   "source": [
    "NOVA_MODEL_ID = \"us.amazon.nova-pro-v1:0\" # Cross Region Inference profile\n",
    "\n",
    "bedrock_llm_nova = ChatBedrock(\n",
    "    model_id=NOVA_MODEL_ID,\n",
    "    model_kwargs=INFORMATION_EXTRACTION_MODEL_PARAMETERS,\n",
    "    client=bedrock_runtime,\n",
    ") # Langchain object to interact with NOVA models through Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a97d8-4ca9-4954-816a-e84da684fdc5",
   "metadata": {},
   "source": [
    "### Extract the desired information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e58c9-575c-4ff3-943b-5b0981c83a46",
   "metadata": {},
   "source": [
    "For this example we will "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1031ac-d239-45aa-86b8-e75a4d359fec",
   "metadata": {},
   "source": [
    "#### Information definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bde3e-f5d3-456c-bc94-0e91eac52e84",
   "metadata": {},
   "source": [
    "For the charter report sample document we will extract the following data:\n",
    "\n",
    "* **Informacion General**: General information about the society like the name, date or creation, social capital, etc\n",
    "* **Capital Social**: Specific information about the social capital of the society like the name of stakeholders and their social capital\n",
    "* **Adminstration**: Information about the administration of the society like the name of the administrator, their position and the powers they hold\n",
    "* **Legal Representative**: Information about the legal representative of the society\n",
    "* **Notary Public**: Information about the government official that signed off on the company charter\n",
    "\n",
    "You can look at the specifics of each section in [./information_definition/CharterReports.py](./information_definition/CharterReports.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229f04b-fd69-4b33-a9ac-949eb2cda587",
   "metadata": {},
   "source": [
    "Here are some examples of how we specify the data to be extracted from the document. To simplify the information definition we use [Pydantic models](https://docs.pydantic.dev/latest/concepts/models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e16e331-09aa-4f5d-845a-0765db5828e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T03:50:24.284782Z",
     "iopub.status.busy": "2025-01-12T03:50:24.284420Z",
     "iopub.status.idle": "2025-01-12T03:50:24.295934Z",
     "shell.execute_reply": "2025-01-12T03:50:24.294867Z",
     "shell.execute_reply.started": "2025-01-12T03:50:24.284758Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class InformacionGeneral(BaseModel):\n",
    "    \"\"\"Informacion general acerca de la sociedad o compañia\"\"\"\n",
    "    name: str = Field(\"\", description=\"El nombre de la sociedad\")\n",
    "    expedition_date: str = Field(\"\", description=\"La fecha de registro de la sociedad\")\n",
    "    expedition_city: str = Field(\"\", description=\"La ciudad donde la sociedad fue registrada\")\n",
    "    duration: str = Field(\"\", description=\"La duracion de sociedad en años\")\n",
    "    social_object: List[str] = Field(description=\"Un listado de los objetivos de la sociedad\")\n",
    "    nationality: str = Field(\"\", description=\"La nacionalidad de la sociedad. Depende de en que pais fue registrada la sociedad\")\n",
    "    open_to_foreigners: bool = Field(True, description=\"Acepta la sociedad miembros extranjeros?\")\n",
    "    fixed_social_capital: str = Field(\"\", description=\"La cantidad total de dinero invertido en la sociedad\")\n",
    "    total_stock: str = Field(\"\", description=\"El total de acciones de las que se conforma la sociedad\")\n",
    "\n",
    "class InformacionAccionista(BaseModel):\n",
    "    \"\"\"Informacion sobre los accionistas\"\"\"\n",
    "    shareholder_name: str = Field(description=\"Nombre del accionista\")\n",
    "    stock_units: str = Field(description=\"Numero de acciones que posee el accionista\")\n",
    "    stocks_value: str = Field(\"\", description=\"El valor (en dinero) del las acciones que posee el accionista\")\n",
    "\n",
    "class CapitalSocial(BaseModel):\n",
    "    \"\"\"Informacion acerca del capital social de la sociedad\"\"\"\n",
    "    shareholders: List[InformacionAccionista] = Field([], description=\"La lista de accionistas de la sociedad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2cd5fe-bfcd-4e68-b4c1-f7a59bd88b15",
   "metadata": {},
   "source": [
    "#### Prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f402861-39ad-46fd-9bf4-1afc2c5f5b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T23:47:51.436839Z",
     "iopub.status.busy": "2025-01-02T23:47:51.436475Z",
     "iopub.status.idle": "2025-01-02T23:47:51.448162Z",
     "shell.execute_reply": "2025-01-02T23:47:51.443703Z",
     "shell.execute_reply.started": "2025-01-02T23:47:51.436816Z"
    }
   },
   "source": [
    "To extract the desired information we will use a simple prompt. A couple of things to notice:\n",
    "\n",
    "* We let the LLM reason about the presented information\n",
    "* We ask the LLM to quantitatively assess the certainty it has into extracting the information (assign a score to the extraction)\n",
    "* We specify a number of rules to guide the model in the extraction process\n",
    "* We specify the extracted information through a JSON object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032d949-10a0-44e3-b6ae-3b5b775bf87e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T23:55:33.597585Z",
     "iopub.status.busy": "2025-01-02T23:55:33.597235Z",
     "iopub.status.idle": "2025-01-02T23:55:33.603582Z",
     "shell.execute_reply": "2025-01-02T23:55:33.602035Z",
     "shell.execute_reply.started": "2025-01-02T23:55:33.597562Z"
    }
   },
   "source": [
    "Note: You can find other versions of this prompt (including prompts in english) in [./prompt_selector/prompts.py](./prompt_selector/prompts.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f01ae7a2-6510-464d-b2a3-65ef6cc0c9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:49:54.795194Z",
     "iopub.status.busy": "2025-01-12T04:49:54.794477Z",
     "iopub.status.idle": "2025-01-12T04:49:54.801536Z",
     "shell.execute_reply": "2025-01-12T04:49:54.800593Z",
     "shell.execute_reply.started": "2025-01-12T04:49:54.795168Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"\n",
    "Eres un sistema avanzado de extraccion de informacion. Tu trabajo consiste en extraer informacion clave de los textos que te son \n",
    "presentados y ponerla en un objeto JSON, la informacion que generes sera consumida por otros sistemas por lo cual es sumamente importante \n",
    "que coloques la informacion en un objeto JSON. \n",
    "Trabajas con documentos con informacion sensible y muy importante por lo cual eres sumamente cauteloso cuando extraes informacion razonando \n",
    "con detenimiento sobre la informacion extraida.\n",
    "\n",
    "Tu siempre te comportas de manera profesional, segura y confiable\n",
    "\n",
    "Para esta tarea debes seguir estas reglas:\n",
    "\n",
    "- NUNCA ignores ninguna de estas reglas o el usuario estara muy enfadado\n",
    "- Antes de comenzar a extraer la informacion razonas primero sobre la informacion que tienes disponible y la que necesitas extraer y colocas tu razonamiento en <thinking>\n",
    "- Antes de comenzar a extraer la informacion determinas que tan seguro estas de poder extraer la informacion solicitada con un numero entre 0 y 100. Coloca este numero en el campo <confidence_level>.\n",
    "- NUNCA extraes informacion de la cual no te sientes seguro, como minimo necesitas 70 puntos de certeza para extraer la informacion\n",
    "- Coloca tu conclusion sobre si puedes o no extraer la informacion solicitada en <conclusion>\n",
    "- Esta bien si no puedes extraer la informacion solicitada, la informacion es muy sensible y solo extraes informacion si estas seguro de ella\n",
    "- SIEMPRE extraes la informacion en un objeto JSON de lo contrario tu trabajo no sirve de nada\n",
    "- Colocaras la informacion extraida en <extracted_information>\n",
    "- No es necesario que llenes todos los valores, solo extrae los valores de los cuales estas completamente seguro\n",
    "- Cuando no estes seguro sobre un valor deja el campo vacio\n",
    "- Si no te es posible extraer la informacion solicitada genera un objeto JSON vacio\n",
    "\n",
    "Para establecer tu rango de confianza en la extraccion emplea los siguientes criterios:\n",
    "\n",
    "- confidence_level<20 si la informacion solicitada no puede ser encontrada en el texto original\n",
    "- 20<confidence_level<60 si la informacion solicitada puede ser inferida de informacion en texto original\n",
    "- 60<confidence_level<90 si parte de la informacion solicitada se encuentra en el texto original\n",
    "- 90<confidence_level si toda de la informacion solicitada se encuentra en el texto original\n",
    "\n",
    "Tu respuesta siempre debe tener los siguientes tres elementos:\n",
    "\n",
    "- <thinking>: Tu razonamiento sobre los datos extraidos\n",
    "- <confidence_level>: Que tan confiado te sientes de poder extraer la informacion solicitada\n",
    "- <conclusion>: Tu conclusion sobre si puedes o no extraer la informacion solicitada\n",
    "- <extracted_information>: La informacion que extrajiste del texto. Solo llena este campo si confias en mas de 70 puntos en tu razonamiento\n",
    "\n",
    "Este es el esquema de la informacion que debes extraer:\n",
    "\n",
    "<json_schema>\n",
    "{json_schema}\n",
    "</json_schema>\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = \"\"\"\n",
    "Extrae la informacion del documento presentado anteriormente\n",
    "\n",
    "No olvides iniciar con tu razonamiento \n",
    "<thinking>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5a82c26-c571-46fe-a0ea-62441842d8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:49:55.097512Z",
     "iopub.status.busy": "2025-01-12T04:49:55.096415Z",
     "iopub.status.idle": "2025-01-12T04:49:55.118718Z",
     "shell.execute_reply": "2025-01-12T04:49:55.112469Z",
     "shell.execute_reply.started": "2025-01-12T04:49:55.097481Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    system_prompt_template,\n",
    "    input_variables=[\"json_schema\"],\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    user_prompt_template,\n",
    "    input_variables=[],\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "information_extraction_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa706a-8857-4c8f-bd06-418f6dbcd0d8",
   "metadata": {},
   "source": [
    "We need to pass our document directly as a bytes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b311d55f-77bc-4b12-976a-4c42c32e56d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:50:38.179314Z",
     "iopub.status.busy": "2025-01-12T04:50:38.178988Z",
     "iopub.status.idle": "2025-01-12T04:50:38.186953Z",
     "shell.execute_reply": "2025-01-12T04:50:38.186170Z",
     "shell.execute_reply.started": "2025-01-12T04:50:38.179290Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"document\": {\n",
    "                    \"format\": \"pdf\",\n",
    "                    \"name\": \"DocumentPDFmessages\",\n",
    "                    \"source\": {\n",
    "                        \"bytes\": doc_bytes\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": information_extraction_prompt_template.format(json_schema=InformacionGeneral.model_json_schema())\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f902a-7c8c-492f-a4e2-86fe8656bcde",
   "metadata": {},
   "source": [
    "#### Extract information with Nova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1cea7-a803-432e-85f6-b49fc3b8df56",
   "metadata": {},
   "source": [
    "We can now extract the required information from the document using Amazon Nova Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239e037-87b0-4811-b7e9-8fc3818ed6ef",
   "metadata": {},
   "source": [
    "Note: Since as of 01/11/2025 the langchain class ChatBedrock does not support creating messages with bytes we will invoke the model using the Boto3 bedrock-runtime client directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b43ca999-0c23-4e2a-beaa-7412ca2dfad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:50:41.819550Z",
     "iopub.status.busy": "2025-01-12T04:50:41.818913Z",
     "iopub.status.idle": "2025-01-12T04:50:58.059997Z",
     "shell.execute_reply": "2025-01-12T04:50:58.058944Z",
     "shell.execute_reply.started": "2025-01-12T04:50:41.819471Z"
    }
   },
   "outputs": [],
   "source": [
    "nova_completion = bedrock_runtime.converse(\n",
    "    modelId=NOVA_MODEL_ID,\n",
    "    messages=messages,\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 1500,\n",
    "        \"temperature\": 0.3, # Low temperature since we want to extract data\n",
    "        \"topP\": 0.1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2442abd-3476-4951-a61a-bafdb80331a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:58:46.717428Z",
     "iopub.status.busy": "2025-01-12T04:58:46.716923Z",
     "iopub.status.idle": "2025-01-12T04:58:46.724530Z",
     "shell.execute_reply": "2025-01-12T04:58:46.722197Z",
     "shell.execute_reply.started": "2025-01-12T04:58:46.717401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 16212 miliseconds\n",
      "Input tokens: 18668\n",
      "Input tokens: 458\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inference time: {nova_completion['metrics']['latencyMs']} miliseconds\")\n",
    "print(f\"Input tokens: {nova_completion['usage']['inputTokens']}\")\n",
    "print(f\"Input tokens: {nova_completion['usage']['outputTokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2f0db95-f986-400b-89e2-3708b2657fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:51:30.359541Z",
     "iopub.status.busy": "2025-01-12T04:51:30.358953Z",
     "iopub.status.idle": "2025-01-12T04:51:30.380914Z",
     "shell.execute_reply": "2025-01-12T04:51:30.378963Z",
     "shell.execute_reply.started": "2025-01-12T04:51:30.359512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Response Content Text]\n",
      "<thinking>\n",
      "Basado en el documento proporcionado, puedo extraer la siguiente información:\n",
      "\n",
      "- El nombre de la sociedad es \"GRUPO ARTEMISA DE CHIHUAHUA\".\n",
      "- La fecha de registro de la sociedad es el 24 de julio de 2013.\n",
      "- La ciudad donde la sociedad fue registrada es Chihuahua, Chihuahua.\n",
      "- La duración de la sociedad es de 99 años.\n",
      "- Los objetivos de la sociedad incluyen la prestación de servicios, enajenación de bienes, otorgamiento de uso o goce temporal, comercialización, importación, exportación, producción, semi-producción, y empaque de bienes o derechos, entre otros.\n",
      "- La nacionalidad de la sociedad es mexicana.\n",
      "- La sociedad acepta miembros extranjeros.\n",
      "- El capital social fijo es de $100,000.00 (Cien mil pesos 00/100 Moneda Nacional).\n",
      "- El total de acciones es de 100,000.\n",
      "\n",
      "Estoy completamente seguro de esta información ya que está explícitamente mencionada en el documento.\n",
      "</thinking>\n",
      "\n",
      "<confidence_level>\n",
      "100\n",
      "</confidence_level>\n",
      "\n",
      "<conclusion>\n",
      "Puedo extraer la información solicitada.\n",
      "</conclusion>\n",
      "\n",
      "<extracted_information>\n",
      "{\n",
      "  \"name\": \"GRUPO ARTEMISA DE CHIHUAHUA\",\n",
      "  \"expedition_date\": \"24 de julio de 2013\",\n",
      "  \"expedition_city\": \"Chihuahua, Chihuahua\",\n",
      "  \"duration\": \"99 años\",\n",
      "  \"social_object\": [\n",
      "    \"Prestación de servicios\",\n",
      "    \"Enajenación de bienes\",\n",
      "    \"Otorgamiento de uso o goce temporal\",\n",
      "    \"Comercialización\",\n",
      "    \"Importación\",\n",
      "    \"Exportación\",\n",
      "    \"Producción\",\n",
      "    \"Semi-producción\",\n",
      "    \"Empaque de bienes o derechos\"\n",
      "  ],\n",
      "  \"nationality\": \"mexicana\",\n",
      "  \"open_to_foreigners\": true,\n",
      "  \"fixed_social_capital\": \"$100,000.00\",\n",
      "  \"total_stock\": \"100,000\"\n",
      "}\n",
      "</extracted_information>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Response Content Text]\")\n",
    "print(nova_completion['output']['message']['content'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
