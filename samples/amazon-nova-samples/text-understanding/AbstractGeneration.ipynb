{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00e49e6-6ff6-481a-8109-da356a2fa167",
   "metadata": {},
   "source": [
    "# Amazon Nova text generation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba300f-8493-48f2-a18f-f407daedff5a",
   "metadata": {},
   "source": [
    "In this notebook we will demonstrate how to use [Amazon Nova *understanding* models](https://aws.amazon.com/ai/generative-ai/nova/) for various text generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620855d-9892-44bb-99df-af05e412e1c1",
   "metadata": {},
   "source": [
    "To execute the cells in this notebook you need to enable access to the following models on Bedrock:\n",
    "\n",
    "* Amazon Nova Micro\n",
    "* Amazon Nova Lite\n",
    "* Anthropic Claude Haiku 3\n",
    "\n",
    "see [Add or remove access to Amazon Bedrock foundation models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html) to manage the access to models in Amazon Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43838e54-24cb-43e3-aa9e-8becc09774ca",
   "metadata": {},
   "source": [
    "Note: This notebook uses [Langchain](https://www.langchain.com/) to orchestrate the flow of the generative AI application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ec34a-849b-43ab-9563-d58de92b95ad",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc6ee6-6733-4ab5-b548-a76056a10cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-aws langchain-core langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a7e41-900a-4ca9-8f9a-59ddf7a96408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import langchain_core\n",
    "import pydantic\n",
    "import base64\n",
    "import time\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50146183-3c21-4b6a-b7cc-9dff01dab5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=Config(retries={'max_attempts': 20})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf77dc-b1db-48d6-a5bc-a6ac813a7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_core.globals.set_debug(True) # Set to True for enabling debugging stack traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e6887-a560-426f-96e5-2272464b0fad",
   "metadata": {},
   "source": [
    "## Quickly generate abstracts for your technical sessions with Nova Micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebd0ec-f748-4082-9f8f-409e6465c327",
   "metadata": {},
   "source": [
    "[Amazon Nova Micro](https://docs.aws.amazon.com/ai/responsible-ai/nova-micro-lite-pro/overview.html) is the most lightweight, fast, and cost-effective text generation model of the Amazon Nova family. Its ideal for tasks such as:\n",
    "\n",
    "* Q&A\n",
    "* Summarization\n",
    "* Translation\n",
    "* Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae234d0-e3c4-4347-9a1c-4664357c2a6e",
   "metadata": {},
   "source": [
    "In this example we will use Amazon Nova Micro to quickly create high quality abstracts for technical presentations using as input the description of the topics that the presentation will cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df1886-47f5-479e-8651-b27e51a9780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_GENERATION_MODEL_PARAMETERS = {\n",
    "    \"max_tokens\": 1500,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b3908-69f1-45e0-ab7a-18532efc2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOVA_MICRO_MODEL_ID = \"us.amazon.nova-micro-v1:0\" # Cross Region Inference profile\n",
    "NOVA_LITE_MODEL_ID = \"us.amazon.nova-lite-v1:0\" # Cross Region Inference profile\n",
    "CLAUDE_MODEL_ID = \"us.anthropic.claude-3-haiku-20240307-v1:0\" # Cross Region Inference profile\n",
    "\n",
    "bedrock_llm_nova_micro = ChatBedrock(\n",
    "    model_id=NOVA_MICRO_MODEL_ID,\n",
    "    model_kwargs=ABSTRACT_GENERATION_MODEL_PARAMETERS,\n",
    "    client=bedrock_runtime,\n",
    ") # Langchain object to interact with NOVA models through Bedrock\n",
    "\n",
    "bedrock_llm_nova_lite = ChatBedrock(\n",
    "    model_id=NOVA_LITE_MODEL_ID,\n",
    "    model_kwargs=ABSTRACT_GENERATION_MODEL_PARAMETERS,\n",
    "    client=bedrock_runtime,\n",
    ") # We use Nova Lite for comparisson purposes\n",
    "\n",
    "bedrock_llm_haiku3 = ChatBedrock(\n",
    "    model_id=CLAUDE_MODEL_ID,\n",
    "    model_kwargs=ABSTRACT_GENERATION_MODEL_PARAMETERS,\n",
    "    client=bedrock_runtime,\n",
    ") # We use Claude 3 for comparisson purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e7183-0234-43d3-940e-ded97cde075c",
   "metadata": {},
   "source": [
    "### Create a prompt for creating abstracts from the topics that will be included in the presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b537d-fee1-4dfe-b024-aca75600f735",
   "metadata": {},
   "source": [
    "This prompt follows the guidelines published in: [https://aws.amazon.com/blogs/machine-learning/prompt-engineering-techniques-and-best-practices-learn-by-doing-with-anthropics-claude-3-on-amazon-bedrock/](https://aws.amazon.com/blogs/machine-learning/prompt-engineering-techniques-and-best-practices-learn-by-doing-with-anthropics-claude-3-on-amazon-bedrock/) and [https://docs.aws.amazon.com/nova/latest/userguide/prompting.html](https://docs.aws.amazon.com/nova/latest/userguide/prompting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c5cfb-2f65-4899-a63d-5a42624e19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_CREATION_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are tech worker who is very skilled in writing abstracts for public speaking \n",
    "technical conferences. Your task is to write sessions abstract in a professional, \n",
    "concise way. \n",
    "\n",
    "You are very to the point when writing your abstracts and always use a semi-formal \n",
    "tone. \n",
    "\n",
    "Here are some rules for your consideration when writing the abstract: \n",
    "\n",
    "* Abstracts should clearly state the use case/problem and which public is being \n",
    "addressed or will benefit from attending the session, e.g. “In this session \n",
    "data scientist will learn how to build gen ai applications using AWS Bedrock”. \n",
    "\n",
    "* The abstract should clearly state the benefits/outcomes attendees will get out \n",
    "of the session; if a customer is presenting make sure to note what the customer \n",
    "will add to the conversation e.g. “Joins us to learn how WEG implemented, \n",
    "using SageMaker JumpStart pre-trained models, a text summarization system to \n",
    "reduce machinery troubleshooting from days to hours”. \n",
    "\n",
    "* If possible, close the abstract with a call to action e.g. “Join this session \n",
    "and learn how to build reliable ML systems at scale with AWS SageMaker”.\n",
    "\n",
    "* Keep the abstract below 120 words (about 600 characters)\n",
    "\n",
    "Here are some good examples for you: \n",
    "\n",
    "<examples> \n",
    "\n",
    "<good_abstract> \n",
    "Prompt engineering is the process of guiding large language models (LLMs) to \n",
    "produce desired outputs. In this session, get an overview of prompt engineering \n",
    "best practices and learn how to choose the most appropriate formats, phrases, \n",
    "words, and symbols to get the most out of generative AI solutions while improving \n",
    "accuracy and performance. This session uses the Claude 2 LLM as an example of how \n",
    "prompt engineering helps to solve complex customer use cases. Also learn how \n",
    "prompts can be integrated with your architecture and how to use API parameters for \n",
    "tuning the model parameters using Amazon Bedrock. \n",
    "</good_abstract> \n",
    "\n",
    "<good_abstract> \n",
    "Omics data holds great promise for improving health outcomes and accelerating \n",
    "scientific discovery, but analyzing large, complex genomic and multiomics datasets \n",
    "presents challenges. Storing, accessing, and deriving understanding from these data \n",
    "requires specialized tools. Learn how Amgen, a leading biopharma company, overcomes \n",
    "these hurdles using AWS HealthOmics, a purpose-built genomics cloud service, to \n",
    "transform different types of omics data into insights. Hear how Amgen uses the \n",
    "secure storage and scalable workflows of HealthOmics to efficiently generate \n",
    "insights from high-volume omics data. Using HealthOmics, researchers can transform \n",
    "genomics big data into useful knowledge, leading to advances in medicine and \n",
    "scientific breakthroughs. \n",
    "</good_abstract> \n",
    "\n",
    "<good_abstract> \n",
    "We are truly at an exciting inflection point in the widespread adoption of ML \n",
    "with the growth of generative AI applications. In this session, learn how to build \n",
    "your first generative AI application with key services such as Amazon Bedrock. \n",
    "Get hints and tips for getting started fast, and see example reference architectures \n",
    "for common use cases built with AWS AI and ML such as self-service customer support, \n",
    "text analysis, report generation, post-call analysis, and forecasting trends. \n",
    "</good_abstract> \n",
    "\n",
    "<good_abstract> \n",
    "Unexpected equipment failure is costly for industrial facilities. But scheduling \n",
    "maintenance too frequently wastes resources. In this session, hear from Koch Ag & \n",
    "Energy Solutions (KAES) on how they use Amazon Monitron to implement predictive \n",
    "maintenance across their industrial machinery. Learn how, with Amazon Monitron’s \n",
    "wireless sensors and machine learning, you can reduce unplanned downtime and \n",
    "transform maintenance operations to be data-driven and proactive. \n",
    "</good_abstract> \n",
    "\n",
    "</examples> \n",
    "\n",
    "Create a an abstract for a session that will present the content in <content> XML \n",
    "tags to a technical audience. The content is made up of several <source> sections. \n",
    "Be professional and concise and output the resulting abstract in the <abstract> XML \n",
    "tags. Do not add a premable to your answer.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ABSTRACT_CREATION_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Create an abstract for a session that will presente the following content\n",
    "\n",
    "<content> \n",
    "{session_content}\n",
    "</content>\n",
    "\n",
    "Please output your answer in Spanish\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2360f3-2676-4a33-8dc5-3cc51dca6701",
   "metadata": {},
   "source": [
    "For the content we compile some announcements from [\"Whats new with AWS\"](https://aws.amazon.com/new/?whats-new-content-all.sort-by=item.additionalFields.postDateTime&whats-new-content-all.sort-order=desc&awsf.whats-new-categories=*all). In this case we selected some announcements for Amazon Q.\n",
    "\n",
    "You are encouraged to make your own compilation of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6482cb-fc7d-4db0-bc0c-380c0b4795a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_content = \"\"\"\n",
    "<source>\n",
    "Starting today, Amazon Q Developer can also perform code reviews, automatically \n",
    "providing comments on your code in the IDE, flagging suspicious code patterns, \n",
    "providing patches where available, and even assessing deployment risk so you can \n",
    "get feedback on your code quickly.\n",
    "\n",
    "Q Developer is a generative AI-powered assistant for designing, building, testing, \n",
    "deploying, and maintaining software. Its agents for software development have a \n",
    "deep understanding of your entire code repos, so they can accelerate many tasks \n",
    "beyond coding. By automating the first round of code reviews and improving review \n",
    "consistency, Q Developer empowers code authors to fix issues faster, streamlining \n",
    "the process for both authors and reviewers. With this new capability, Q Developer \n",
    "can help you get immediate feedback for your code reviews and code fixes where \n",
    "available, so you can increase the speed of iteration and improve the quality of \n",
    "your code.\n",
    "\n",
    "This capability is available in the integrated development environment (IDE) through \n",
    "a new chat command: /review. You can start automating code reviews via the Visual \n",
    "Studio Code and IntelliJ IDEA Integrated Development Environments (IDEs) with both \n",
    "an Amazon Q Developer Free Tier or Pro Tier subscription. For more details on \n",
    "pricing, see Amazon Q Developer pricing. \n",
    "</source>\n",
    "\n",
    "<source>\n",
    "Today, Amazon Q Developer announces the general availability of a new agent that \n",
    "automates the process of generating unit tests. This agent can be easily initiated \n",
    "by using a simple prompt: “/test”. Once prompted, Amazon Q will use the knowledge \n",
    "of your project to automatically generate and add tests to your project, helping \n",
    "improve code quality, fast.\n",
    "\n",
    "Amazon Q Developer will also ask you to provide consent before adding tests, \n",
    "allowing you to always stay in the loop so that no unintended changes are made. \n",
    "Automation saves the time and effort needed to write comprehensive unit tests, \n",
    "allowing you to focus on building innovative features. With the ability to quickly \n",
    "add unit tests and increase coverage across code, organizations can safely and more \n",
    "reliably ship code, accelerating feature development across the software development \n",
    "lifecycle.\n",
    "\n",
    "Automatic unit test generation is generally available within the Visual Studio Code \n",
    "and JetBrains integrated development environments (IDEs) or in public preview as \n",
    "part of the new GitLab Duo with Amazon Q offering, in all AWS Regions where Amazon Q \n",
    "Developer is available. Learn more about unit test generation.\n",
    "</source>\n",
    "\n",
    "<source>\n",
    "Starting today, Amazon Q Developer can document your code by automatically generating \n",
    "readme files and data-flow diagrams within your projects. \n",
    "\n",
    "Today, developers report they spend an average of just one hour per day coding. They \n",
    "spend most of their time on tedious, undifferentiated tasks such as learning \n",
    "codebases, writing and reviewing documentation, testing, managing deployments, \n",
    "troubleshooting issues or finding and fixing vulnerabilities. Q Developer is a \n",
    "generative AI-powered assistant for designing, building, testing, deploying, and \n",
    "maintaining software. Its agents for software development have a deep understanding \n",
    "of your entire code repos, so they can accelerate many tasks beyond coding. With this \n",
    "new capability, Q Developer can help you understand your existing code bases faster, \n",
    "or quickly document new features, so you can focus on shipping features for your \n",
    "customers.\n",
    "\n",
    "This capability is available in the integrated development environment (IDE) through a \n",
    "new chat command: /doc . You can get started generating documentation within the \n",
    "Visual Studio Code and IntelliJ IDEA IDEs with an Amazon Q Developer Free Tier or \n",
    "Pro Tier subscription. For more details on pricing, see Amazon Q Developer pricing.\n",
    "</source>\n",
    "\n",
    "<source>\n",
    "Starting today, you can build ML models using natural language with Amazon Q Developer, \n",
    "now available in Amazon SageMaker Canvas in preview. You can now get generative \n",
    "AI-powered assistance through the ML lifecycle, from data preparation to model \n",
    "deployment. With Amazon Q Developer, users of all skill levels can use natural language\n",
    " to access expert guidance to build high-quality ML models, accelerating innovation and \n",
    " time to market.\n",
    "\n",
    "Amazon Q Developer will break down your objective into specific ML tasks, define the \n",
    "appropriate ML problem type, and apply data preparation techniques to your data. \n",
    "Amazon Q Developer then guides you through the process of building, evaluating, and \n",
    "deploying custom ML models. ML models produced in SageMaker Canvas with Amazon Q \n",
    "Developer are production ready, can be registered in SageMaker Studio, and the code \n",
    "can be shared with data scientists for integration into downstream MLOps workflows.\n",
    "</source>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b3ae0-84f5-4a08-ae81-7541147b1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    ABSTRACT_CREATION_SYSTEM_PROMPT_TEMPLATE,\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "user_prompt_template = HumanMessagePromptTemplate.from_template(\n",
    "    ABSTRACT_CREATION_USER_PROMPT_TEMPLATE,\n",
    "    input_variables=[\"session_content\"],\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "abstract_generation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_prompt_template,\n",
    "    user_prompt_template\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c404f-5ff3-451d-a077-04f7807d5b23",
   "metadata": {},
   "source": [
    "### Generate abstract using Amazon Nova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be3fac-5531-49ba-a839-8bea1707773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_abstract_nova_micro = abstract_generation_prompt_template | bedrock_llm_nova_micro\n",
    "\n",
    "start_time = time.time()\n",
    "nova_completion_micro = langchain_abstract_nova_micro.invoke({ \n",
    "    \"session_content\":session_content,\n",
    "})\n",
    "time_micro = time.time() - start_time # Probably not the best way to compute execution time but it is convenient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9b421-1a06-4d9b-a8bc-cabade36073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_abstract_nova_lite = abstract_generation_prompt_template | bedrock_llm_nova_lite\n",
    "\n",
    "start_time = time.time()\n",
    "nova_completion_lite = langchain_abstract_nova_lite.invoke({ \n",
    "    \"session_content\":session_content,\n",
    "})\n",
    "time_lite = time.time() - start_time # Probably not the best way to compute execution time but it is convenient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d05c87-7358-4fe7-a1bd-22d8be02dc92",
   "metadata": {},
   "source": [
    "### Generate abstract using Anthropic Claude 3 Haiku"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8a440-2b3e-49de-909a-f945188d52a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T23:32:55.927547Z",
     "iopub.status.busy": "2025-01-08T23:32:55.926977Z",
     "iopub.status.idle": "2025-01-08T23:32:55.940099Z",
     "shell.execute_reply": "2025-01-08T23:32:55.938433Z",
     "shell.execute_reply.started": "2025-01-08T23:32:55.927521Z"
    }
   },
   "source": [
    "We now execute the same workload with Anthropic's Claude 3 Haiku model for comparisson purposes. Notice how easy it is to switch models using [Bedrock's Converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html). Also notice how we use the same prompt template as Nova's prompt template since the general principles for prompting apply to both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc96b77-d7e4-4ed4-8be5-d71debf53e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_abstract_claude = abstract_generation_prompt_template | bedrock_llm_haiku3\n",
    "\n",
    "start_time = time.time()\n",
    "claude_completion = langchain_abstract_claude.invoke({ \n",
    "    \"session_content\":session_content,\n",
    "})\n",
    "time_claude = time.time() - start_time # Probably not the best way to compute execution time but it is convenient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b41c3-1052-403d-8b46-f24adb3c0206",
   "metadata": {},
   "source": [
    "### Side by side results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355ede5-96fe-4ae6-b73b-0cab91bceb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Amazon Nova Micro: \\n\\n{nova_completion_micro.content}\\n\\n\\nAmazon Nova Lite: \\n\\n{nova_completion_lite.content}\\n\\n\\n Anthropic Claude 3 Haiku: \\n\\n{claude_completion.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b460f8-220e-4ee0-b98d-0bc2933391ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nAmazon Nova Micro\\n\")\n",
    "print(f\"Inference time: {nova_completion_micro.response_metadata['metrics']['latencyMs'][0]} miliseconds\")\n",
    "print(f\"Execution time {time_micro} seconds\")\n",
    "print(f\"Input tokens: {nova_completion_micro.usage_metadata['input_tokens']}\")\n",
    "print(f\"Input tokens: {nova_completion_micro.usage_metadata['output_tokens']}\")\n",
    "\n",
    "print(\"\\n\\nAmazon Nova Lite\\n\")\n",
    "print(f\"Inference time: {nova_completion_lite.response_metadata['metrics']['latencyMs'][0]} miliseconds\")\n",
    "print(f\"Execution time {time_lite} seconds\")\n",
    "print(f\"Input tokens: {nova_completion_lite.usage_metadata['input_tokens']}\")\n",
    "print(f\"Input tokens: {nova_completion_lite.usage_metadata['output_tokens']}\")\n",
    "\n",
    "print(\"\\n\\nAnthropic Claude Haiku 3\\n\")\n",
    "print(f\"Execution time {time_claude} seconds\")\n",
    "print(f\"Input tokens: {claude_completion.usage_metadata['input_tokens']}\")\n",
    "print(f\"Input tokens: {claude_completion.usage_metadata['output_tokens']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
